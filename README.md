
# deepseekMine检索测试与生成性能测试说明

本说明文档详细介绍了deepseekMine检索测试与生成性能测试的操作流程，涵盖逐步上传与一次性上传两种模式，并附带环境安装说明，便于快速上手。

## 环境准备

1. **安装依赖环境**
    - 请确保已安装 Python 3.10 及以上版本。
    - 使用如下命令安装依赖包：

```bash
pip install -r requirements.txt
```

## 检索测试操作说明

### 1. 逐步上传模式

- **测试脚本：** `rag_retrieval_eval.py`
- **参数说明：**
    - `--dataset`：数据集名称（`zh_int` 或 `zh_refine`）
    - `--noise_rate`：噪声比率（如 0.0、0.2、0.4、0.6、0.8）
    - `--num`：每组测试数量
- **示例代码：**

```python
import os

noise_rates = [0.0, 0.2, 0.4, 0.6, 0.8]
for rate in noise_rates:
    cmd = f"python rag_retrieval_eval.py --dataset zh_int --noise_rate {rate} --num 5"
    os.system(cmd)
```

> 可将 `zh_int` 替换为 `zh_refine` 以测试不同数据集。


### 2. 一次性上传模式

- **测试命令：**

```bash
python rag_retrieval_eval.py --dataset zh_refine --all_in_one_upload
python rag_retrieval_eval.py --dataset zh_int --all_in_one_upload
```

> 分别测试 `zh_refine` 和 `zh_int` 数据集的一次性上传检索效果。


## 生成性能测试操作说明

### 1. 逐步上传模式

- **测试脚本：**
    - `test_deepseek.py`
    - `test_Qwen3.py`
- **操作方式：**
    - 分别运行上述脚本，测试不同模型的生成性能。


### 2. 一次性上传模式

- **准备数据：**
    - 先上传合并后的文档文件：
        - `merged_all_docs.txt1`（对应 `zh_refine`）
        - `merged_all_docs.txt2`（对应 `zh_int`）
- **运行脚本：**
    - 执行 `auto.py`，并根据需要修改参数以分别测试不同数据集。

```bash
python auto.py
```


## 常见问题与建议

- 若遇到依赖包缺失，请根据错误提示补充安装。
- 建议在虚拟环境下运行，避免依赖冲突。
- 必须在打开deepseekMine运行的同时才能进行测试
```

如有其他问题，请联系我

## 模型性能对比表（DeepSeek-R1 \& Qwen3）

本报告整理了 DeepSeek-R1 与 Qwen3 各规模模型在 **噪声鲁棒性测试（zh_refine）** 和 **信息整合能力测试（zh_int）** 下的准确率表现，涵盖不同噪声等级（0.0 ~ 1.0）及参数规模。所有数据均为多次实验平均值，部分附有标准差。

---

### 📊 DeepSeek-R1 各规模模型性能对比（平均值 ± 标准差）

| 模型名 | 0.0 | 0.2 | 0.4 | 0.6 | 0.8 | 1.0 | 信息整合能力（zh_int） |
| :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- |
| deepseek-r1:1.5b | 98.08% (±0.83) | 95.67% (±0.39) | 95.17% (±1.00) | 89.75% (±1.72) | 64.75% (±0.60) | 2.25% (±0.74) | 60.00% (±3.56) |
| deepseek-r1:7b | 98.67% (±0.27) | 97.83% (±0.33) | 96.92% (±1.52) | 95.67% (±0.28) | 82.00% (±0.97) | 4.42% (±0.91) | 72.50% (±3.32) |
| deepseek-r1:8b | 99.17% (±0.15) | 98.42% (±0.62) | 97.75% (±0.15) | 97.17% (±0.67) | 86.42% (±1.59) | 5.92% (±0.61) | 76.25% (±2.22) |


---

### 📊 Qwen3 各规模模型性能对比（平均值 ± 标准差）

| 模型 | 0.0 | 0.2 | 0.4 | 0.6 | 0.8 | 1.0 | 信息整合能力（zh_int） |
| :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- |
| 0.6B | 98.58% (±0.32) | 98.25% (±0.99) | 96.34% (±0.77) | 94.92% (±1.77) | 76.50% (±1.35) | 3.25% (±1.29) | 60.75% (±3.69) |
| 1.7B | 99.33% (±0.00) | 99.50% (±0.20) | 98.58% (±0.32) | 98.50% (±0.43) | 90.25% (±1.37) | 8.84% (±0.19) | 78.44% (±1.38) |
| 4B | 99.25% (±0.16) | 98.92% (±0.16) | 98.83% (±0.34) | 98.25% (±0.50) | 92.25% (±0.50) | 17.92% (±2.42) | 81.73% (±7.43) |
| 8B | 99.17% (±0.33) | 98.33% (±0.91) | 97.92% (±0.74) | 97.24% (±1.35) | 91.15% (±2.66) | 23.96% (±2.04) | 80.60% (±6.19) |


---

### 📊 模型规模与平均准确率对比（综合）

| 模型 | zh_refine 准确率 | zh_int 准确率 |
| :-- | :-- | :-- |
| deepseek-r1-1.5B | 81.67% | 21.00% |
| deepseek-r1-7B | 86.33% | 32.00% |
| deepseek-r1-8B | 87.33% | 36.00% |
| qwen3-0.6B | 86.00% | 24.00% |
| qwen3-1.7B | 88.67% | 37.00% |
| qwen3-4B | **92.31%** | **49.45%** |
| qwen3-8B | 90.81% | 47.25% |


---

### 📌 关键分析

- **模型稳定性**：Qwen3-1.7B在0.0噪声下标准差为0，表现最稳定；Qwen3-8B在0.6噪声下波动最大。
- **抗噪声能力**：在1.0噪声率下，Qwen3-8B准确率最高（23.96%），Qwen3-0.6B最低（3.25%）。
- **规模效益**：信息整合能力（zh_int）随模型规模增大而提升，但Qwen3 4B与8B间存在轻微倒挂，可能与训练细节有关。

---

### 📂 数据集统计信息

| 数据集名称 | 总字符数 | 正样本比例 | 负样本比例 |
| :-- | :-- | :-- | :-- |
| zh_refine | 1,470,972 | 31.53% (463,825) | 68.47% (1,007,147) |
| zh_int | 1,167,197 | 25.49% (297,465) | 74.51% (869,732) |


---

> **注**：所有准确率均为多次实验平均值，标准差反映模型表现稳定性。表格便于横向对比不同规模模型在噪声鲁棒性和信息整合能力两项任务下的表现。


